{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare paths and globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = 'final_weights.h5'\n",
    "TEST_DATA_PATH = \"UrbanSound8k/tfRecords/fold\"\n",
    "TEST_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tfRecord utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def parse_tfrecord(example):\n",
    "    ''' It is strange you need to use tf.string to read in an image '''\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    example[\"image\"] = tf.io.decode_png(example[\"image\"], channels=3)\n",
    "    image = example['image']\n",
    "    target = example['target']\n",
    "    target_hot = tf.one_hot(target, 10)\n",
    "    return (image,target_hot)\n",
    "\n",
    "def get_dataset(record_files):\n",
    "    dataset = tf.data.TFRecordDataset(record_files, buffer_size=100)\n",
    "    dataset = dataset.map(parse_tfrecord, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEfficientNetB4(input_shape=(128, 250, 3)):\n",
    "    # Load base model\n",
    "    base_model = tf.keras.applications.EfficientNetB4(\n",
    "        weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "    )\n",
    "    feat_ex = tf.keras.Model(base_model.input, base_model.output)\n",
    "\n",
    "    # Add new layers\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "    x = feat_ex(inputs)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    yh = layers.Dense(\n",
    "        10, kernel_regularizer=regularizers.l2(0.0001), activation=\"softmax\"\n",
    "    )(x)\n",
    "    model = tf.keras.Model(inputs, yh)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 250, 3)]     0         \n",
      "_________________________________________________________________\n",
      "model (Functional)           (None, 4, 8, 1792)        17673823  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                17930     \n",
      "=================================================================\n",
      "Total params: 17,691,753\n",
      "Trainable params: 17,566,546\n",
      "Non-trainable params: 125,207\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = getEfficientNetB4()\n",
    "model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=opt,loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[\"accuracy\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loaded weights over UrbanSound8k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, [2, 3, 4, 5, 6, 7, 8, 9, 10]), (2, [1, 3, 4, 5, 6, 7, 8, 9, 10]), (3, [1, 2, 4, 5, 6, 7, 8, 9, 10]), (4, [1, 2, 3, 5, 6, 7, 8, 9, 10]), (5, [1, 2, 3, 4, 6, 7, 8, 9, 10]), (6, [1, 2, 3, 4, 5, 7, 8, 9, 10]), (7, [1, 2, 3, 4, 5, 6, 8, 9, 10]), (8, [1, 2, 3, 4, 5, 6, 7, 9, 10]), (9, [1, 2, 3, 4, 5, 6, 7, 8, 10]), (10, [1, 2, 3, 4, 5, 6, 7, 8, 9])]\n"
     ]
    }
   ],
   "source": [
    "folds = []\n",
    "for f in range(1, 11):\n",
    "    fold = [i for i in range(1, 11) if i != f]\n",
    "    folds.append((f, fold))\n",
    "print(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Evaluate on test data\n",
      "14/14 [==============================] - 45s 3s/step - loss: 0.0974 - accuracy: 0.9580\n",
      "[0.12225078046321869, 0.9507445693016052]\n",
      "Fold 2\n",
      "Evaluate on test data\n",
      "14/14 [==============================] - 41s 3s/step - loss: 0.0634 - accuracy: 0.9797\n",
      "[0.06343276798725128, 0.9797297120094299]\n",
      "Fold 3\n",
      "Evaluate on test data\n",
      "15/15 [==============================] - 42s 3s/step - loss: 0.0151 - accuracy: 0.9957\n",
      "[0.015061570331454277, 0.9956756830215454]\n",
      "Fold 4\n",
      "Evaluate on test data\n",
      "16/16 [==============================] - 45s 3s/step - loss: 0.0096 - accuracy: 0.9980\n",
      "[0.009582444094121456, 0.9979798197746277]\n",
      "Fold 5\n",
      "Evaluate on test data\n",
      "15/15 [==============================] - 41s 3s/step - loss: 0.0064 - accuracy: 1.0000\n",
      "[0.0063959634862840176, 1.0]\n",
      "Fold 6\n",
      "Evaluate on test data\n",
      "13/13 [==============================] - 36s 3s/step - loss: 0.0073 - accuracy: 0.9988\n",
      "[0.007315364666283131, 0.9987849593162537]\n",
      "Fold 7\n",
      "Evaluate on test data\n",
      "14/14 [==============================] - 38s 3s/step - loss: 0.0046 - accuracy: 1.0000\n",
      "[0.004622075706720352, 1.0]\n",
      "Fold 8\n",
      "Evaluate on test data\n",
      "13/13 [==============================] - 37s 3s/step - loss: 0.0027 - accuracy: 1.0000\n",
      "[0.002733090426772833, 1.0]\n",
      "Fold 9\n",
      "Evaluate on test data\n",
      "13/13 [==============================] - 37s 3s/step - loss: 0.0028 - accuracy: 1.0000\n",
      "[0.0028394293040037155, 1.0]\n",
      "Fold 10\n",
      "Evaluate on test data\n",
      "14/14 [==============================] - 38s 3s/step - loss: 0.6595 - accuracy: 0.8722\n",
      "[0.6595444679260254, 0.8721624612808228]\n"
     ]
    }
   ],
   "source": [
    "for i, fold in enumerate(folds):\n",
    "    print(\"Fold {}\".format(i + 1))\n",
    "    fold_index = i\n",
    "    test_path = TEST_DATA_PATH + str(fold[0]) + \".tfrec\"\n",
    "    test_dataset = get_dataset(test_path).batch(TEST_BATCH_SIZE)\n",
    "    print(\"Evaluate on test data\")\n",
    "    results = model.evaluate(test_dataset)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make into tf lite model \n",
    "https://www.tensorflow.org/lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp-env",
   "language": "python",
   "name": "anaconda-tfp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
